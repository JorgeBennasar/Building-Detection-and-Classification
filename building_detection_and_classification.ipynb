{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyMaRsDZWzoi6e0XbOIm2rnx"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "premium"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Maf0g1DdSxxt",
        "outputId": "8a76c08c-95e3-4756-8241-45b04c6cda4d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import json\n",
        "import os\n",
        "import cv2\n",
        "import copy\n",
        "import random\n",
        "import numpy as np \n",
        "import matplotlib.pyplot as plt\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "from PIL import Image, ImageEnhance\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "IMAGES_PATH = 'drive/MyDrive/challenge/raw'\n",
        "ANNOTATIONS_PATH = 'drive/MyDrive/challenge/annotations'\n",
        "\n",
        "class satellite_dataset(\n",
        "    torch.utils.data.Dataset\n",
        "    ):\n",
        "\n",
        "  def __init__(\n",
        "      self,\n",
        "      mode\n",
        "      ):\n",
        "    \n",
        "    assert mode == 'train' or mode == 'val' or mode == 'test'\n",
        "    self.mode = mode\n",
        "    self.classes = {\n",
        "        'Background': 0,\n",
        "        'Buildings': 1,\n",
        "        'Houses': 2,\n",
        "        'Sheds/Garages': 3\n",
        "    }\n",
        "    \n",
        "    if self.mode == 'train':\n",
        "\n",
        "      rows = [0, 1, 2, 3, 4, 5, 6, 7]\n",
        "\n",
        "    elif self.mode == 'val':\n",
        "\n",
        "      rows = [8]\n",
        "\n",
        "    else:\n",
        "\n",
        "      rows = [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
        "\n",
        "    images, polygons, labels = [], [], []\n",
        "\n",
        "    for row in rows:\n",
        "\n",
        "      for col in range(9):\n",
        "\n",
        "        image = os.path.join(IMAGES_PATH, f'{row}_{col}.png')\n",
        "        \n",
        "        if os.path.isfile(os.path.join(ANNOTATIONS_PATH, f'{row}_{col}.png-annotated.json')) and mode != 'test':\n",
        "\n",
        "          polygons_, labels_ = [], []\n",
        "\n",
        "          with open(os.path.join(ANNOTATIONS_PATH, f'{row}_{col}.png-annotated.json'), 'r') as f:\n",
        "\n",
        "            data = json.load(f) \n",
        "\n",
        "          for i in range(len(data['labels'])):\n",
        "\n",
        "            label = data['labels'][i]['name']\n",
        "\n",
        "            for j in range(len(data['labels'][i]['annotations'])): \n",
        "\n",
        "              polygon = np.array(data['labels'][i]['annotations'][j]['segmentation'])\n",
        "              labels_.append(self.classes[label])\n",
        "              polygons_.append(polygon)\n",
        "\n",
        "          images.append(image)\n",
        "          polygons.append(polygons_)\n",
        "          labels.append(labels_)\n",
        "\n",
        "        elif mode == 'test':\n",
        "\n",
        "          images.append(image)\n",
        "\n",
        "    self.images, self.polygons, self.labels = images, polygons, labels\n",
        "\n",
        "  def __getitem__(\n",
        "      self, \n",
        "      idx\n",
        "      ):\n",
        "    \n",
        "    image = Image.open(self.images[idx]).convert('RGB')\n",
        "\n",
        "    newSize = (500, 500)\n",
        "    oldSize = image.size\n",
        "    image = image.resize(newSize)\n",
        "    imageTensor = transforms.PILToTensor()(image).float()\n",
        "\n",
        "    if self.mode != 'test':\n",
        "\n",
        "      transform = transforms.Compose([transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
        "      imageTensor = transform(imageTensor)\n",
        "\n",
        "      polygons = copy.deepcopy(self.polygons[idx])\n",
        "\n",
        "      for polygon in polygons:\n",
        "\n",
        "        polygon[::2] *= newSize[0] / oldSize[0]\n",
        "        polygon[1::2] *= newSize[1] / oldSize[1]\n",
        "      \n",
        "      labels = self.labels[idx]\n",
        "      imageTensor, polygons = self.augment(imageTensor, polygons)\n",
        "      boxes, masks = [], []\n",
        "\n",
        "      for polygon in polygons:\n",
        "\n",
        "        boxes.append(self.get_box(polygon))\n",
        "        masks.append(self.get_mask(imageTensor, polygon))\n",
        "\n",
        "      boxesTensor = torch.tensor(np.array(boxes), dtype=torch.float32)\n",
        "      labelsTensor = torch.tensor(np.array(labels), dtype=torch.int64)\n",
        "      masksTensor = torch.tensor(np.array(masks), dtype=torch.uint8)\n",
        "      imageIDTensor = torch.tensor([idx])\n",
        "      areaTensor = (boxesTensor[:, 3] - boxesTensor[:, 1]) * (boxesTensor[:, 2] - boxesTensor[:, 0])\n",
        "      iscrowdTensor = torch.zeros((len(polygons),), dtype=torch.int64)\n",
        "\n",
        "      target = {\n",
        "          'boxes': boxesTensor,\n",
        "          'labels': labelsTensor,\n",
        "          'masks': masksTensor,\n",
        "          'image_id': imageIDTensor,\n",
        "          'area': areaTensor,\n",
        "          'iscrowd': iscrowdTensor,\n",
        "          }\n",
        "\n",
        "      return imageTensor, target\n",
        "\n",
        "    else:\n",
        "\n",
        "      transform = transforms.Compose([transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
        "      imageTensor = transform(imageTensor)\n",
        "\n",
        "      return imageTensor, image\n",
        "\n",
        "  def __len__(\n",
        "      self\n",
        "      ):\n",
        "\n",
        "    return len(self.images)\n",
        "\n",
        "  def augment(\n",
        "      self,\n",
        "      image,\n",
        "      polygons\n",
        "      ):\n",
        "\n",
        "    image, polygons = self.horizontal_flip(image, polygons)\n",
        "    image, polygons = self.vertical_flip(image, polygons)\n",
        "\n",
        "    return image, polygons\n",
        "\n",
        "  def horizontal_flip(\n",
        "      self,\n",
        "      image,\n",
        "      polygons\n",
        "      ):\n",
        "    \n",
        "    if random.random() < 0.5:\n",
        "\n",
        "      image = transforms.RandomHorizontalFlip(p=1)(image)\n",
        "\n",
        "      for i, polygon in enumerate(polygons):\n",
        "\n",
        "        polygons[i][::2] = image.numpy().shape[2] - polygon[::2]\n",
        "\n",
        "    return image, polygons\n",
        "\n",
        "  def vertical_flip(\n",
        "      self,\n",
        "      image,\n",
        "      polygons\n",
        "      ):\n",
        "    \n",
        "    if random.random() < 0.5:\n",
        "\n",
        "      image = transforms.RandomVerticalFlip(p=1)(image)\n",
        "\n",
        "      for i, polygon in enumerate(polygons):\n",
        "\n",
        "        polygons[i][1::2] = image.numpy().shape[1] - polygon[1::2]\n",
        "\n",
        "    return image, polygons\n",
        "\n",
        "  def get_box(\n",
        "      self, \n",
        "      polygon\n",
        "      ):\n",
        "\n",
        "    xMin, xMax = min(polygon[::2]), max(polygon[::2])\n",
        "    yMin, yMax = min(polygon[1::2]), max(polygon[1::2])\n",
        "    box = [xMin, yMin, xMax, yMax]\n",
        "    \n",
        "    return box\n",
        "\n",
        "  def get_mask(\n",
        "      self, \n",
        "      image, \n",
        "      polygon\n",
        "      ):\n",
        "\n",
        "    mask = np.zeros((image.numpy().shape[1], image.numpy().shape[2]), dtype=np.uint8)\n",
        "    xPoints = polygon[::2]\n",
        "    yPoints = polygon[1::2]\n",
        "    coordinates = []\n",
        "\n",
        "    for i, xPoint in enumerate(xPoints):\n",
        "\n",
        "      coordinates.append([xPoint, yPoints[i]])\n",
        "\n",
        "    coordinates = np.array(coordinates, dtype=int)\n",
        "    cv2.fillPoly(mask, [coordinates], color=(1))\n",
        "\n",
        "    return mask"
      ],
      "metadata": {
        "id": "anPdQ_NdS2Yu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainDataset = satellite_dataset(mode='train')\n",
        "valDataset = satellite_dataset(mode='val')\n",
        "testDataset = satellite_dataset(mode='test')"
      ],
      "metadata": {
        "id": "Tzx9Ah2Pw70-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def collate_fn(\n",
        "    batch\n",
        "    ):\n",
        "  \n",
        "  return tuple(zip(*batch))\n",
        "\n",
        "class data_loader():\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        trainDataset,\n",
        "        valDataset\n",
        "        ):\n",
        "      \n",
        "      trainBatchSize, valBatchSize = 4, len(valDataset)\n",
        "      numWorkers = 1\n",
        "\n",
        "      self.trainLoader = torch.utils.data.DataLoader(\n",
        "          trainDataset, \n",
        "          batch_size=trainBatchSize,\n",
        "          shuffle=True,\n",
        "          drop_last=True,\n",
        "          num_workers=numWorkers,\n",
        "          collate_fn=collate_fn\n",
        "          )\n",
        "\n",
        "      self.valLoader = torch.utils.data.DataLoader(\n",
        "          valDataset, \n",
        "          batch_size=valBatchSize,\n",
        "          shuffle=True,\n",
        "          drop_last=True,\n",
        "          num_workers=numWorkers,\n",
        "          collate_fn=collate_fn\n",
        "          )"
      ],
      "metadata": {
        "id": "Z4WHwyIfRrWM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! git clone 'https://github.com/pytorch/vision'"
      ],
      "metadata": {
        "id": "e3PgMjmC1_Q4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision\n",
        "import torch.optim as optim\n",
        "import vision.references.detection.utils as utils\n",
        "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
        "from torchvision.models.detection.mask_rcnn import MaskRCNNPredictor\n",
        "\n",
        "class agent():\n",
        "\n",
        "  def __init__(\n",
        "      self,\n",
        "      trainDataset,\n",
        "      valDataset\n",
        "      ):\n",
        "\n",
        "    self.dataLoader = data_loader(trainDataset, valDataset)\n",
        "\n",
        "    numClasses, hiddenLayer = 4, 512\n",
        "\n",
        "    model = torchvision.models.detection.maskrcnn_resnet50_fpn(pretrained=True)\n",
        "    inFeatures = model.roi_heads.box_predictor.cls_score.in_features\n",
        "    model.roi_heads.box_predictor = FastRCNNPredictor(inFeatures, numClasses)\n",
        "    inFeaturesMask = model.roi_heads.mask_predictor.conv5_mask.in_channels\n",
        "    model.roi_heads.mask_predictor = MaskRCNNPredictor(inFeaturesMask, hiddenLayer, numClasses)\n",
        "    self.model = model\n",
        "    self.model.train()\n",
        "\n",
        "    if torch.cuda.is_available():\n",
        "\n",
        "      torch.cuda.manual_seed(1)\n",
        "      self.device = torch.device('cuda')\n",
        "      torch.cuda.set_device(0)\n",
        "\n",
        "    else:\n",
        "\n",
        "      self.device = torch.device('cpu')\n",
        "      torch.manual_seed(1)\n",
        "\n",
        "    lr, weightDecay, betas, eps = 1e-03, 0.0005, (0.9, 0.999), 1e-08\n",
        "    parameters = [p for p in self.model.parameters() if p.requires_grad]\n",
        "    self.optimizer = torch.optim.Adam(parameters, lr=lr, betas=betas, eps=eps, weight_decay=weightDecay, amsgrad=False)\n",
        "\n",
        "    stepSize, gamma = 32, 0.95\n",
        "    self.lrScheduler = torch.optim.lr_scheduler.StepLR(self.optimizer, step_size=stepSize, gamma=gamma)\n",
        "\n",
        "    self.currentEpoch, self.maxEpoch = 0, 40\n",
        "\n",
        "  def run(\n",
        "      self\n",
        "      ):\n",
        "\n",
        "    for epoch in range(1, self.maxEpoch + 1):\n",
        "\n",
        "      self.currentEpoch += 1\n",
        "      self.trainEpoch()\n",
        "      self.lrScheduler.step()\n",
        "\n",
        "  def trainEpoch(\n",
        "      self,\n",
        "      printFreq=4\n",
        "      ):\n",
        "    \n",
        "    self.model.to(self.device)\n",
        "    \n",
        "    trainLogger = utils.MetricLogger(delimiter=\"  \")\n",
        "    trainLogger.add_meter('lr', utils.SmoothedValue(window_size=1, fmt='{value:.6f}'))\n",
        "    header = 'Epoch: [{}]'.format(self.currentEpoch)\n",
        "\n",
        "    for images, targets in trainLogger.log_every(self.dataLoader.trainLoader, printFreq, header):\n",
        "      \n",
        "      images = list(image.to(self.device) for image in images)\n",
        "      targets = [{k: v.to(self.device) for k, v in t.items()} for t in targets]\n",
        "\n",
        "      lossDict = utils.reduce_dict(self.model(images, targets))\n",
        "      losses = sum(loss for loss in lossDict.values())\n",
        "\n",
        "      self.optimizer.zero_grad()\n",
        "\n",
        "      losses.backward()\n",
        "\n",
        "      self.optimizer.step()\n",
        "\n",
        "      trainLogger.update(loss=losses, **lossDict)\n",
        "      trainLogger.update(lr=self.optimizer.param_groups[0][\"lr\"])\n",
        "\n",
        "      self.lrScheduler.step()\n",
        "\n",
        "    with torch.no_grad():\n",
        "\n",
        "      for images, targets in self.dataLoader.valLoader:\n",
        "\n",
        "        images = list(image.to(self.device) for image in images)\n",
        "        targets = [{k: v.to(self.device) for k, v in t.items()} for t in targets]\n",
        "\n",
        "        valLogger = self.model(images, targets)\n",
        "\n",
        "        valLossClassifier, valLossBoxReg, valLossMask, valLossObjectness, valLossRpnBoxReg = valLogger['loss_classifier'].item(), valLogger['loss_box_reg'].item(), valLogger['loss_mask'].item(), valLogger['loss_objectness'].item(), valLogger['loss_rpn_box_reg'].item()\n",
        "        print(f'Epoch: [{self.currentEpoch}]  [Validation]  loss_classifier: {valLossClassifier}  loss_box_reg: {valLossBoxReg}  loss_mask: {valLossMask}  loss_objectness: {valLossObjectness}  loss_rpn_box_reg: {valLossRpnBoxReg}')"
      ],
      "metadata": {
        "id": "Od1MaeanSORG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "myAgent = agent(trainDataset, valDataset)"
      ],
      "metadata": {
        "id": "pkGKIxC0aO0J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "myAgent.run()\n",
        "torch.save(myAgent.model.state_dict(), '/content/drive/MyDrive/Colab Notebooks/model.pth')"
      ],
      "metadata": {
        "id": "_6x6Lah4wR6I"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
