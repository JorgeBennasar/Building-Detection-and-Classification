{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "code.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyO2BP1FHONc3cC5pvz9hs+E",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JorgeBennasar/incubit_challenge/blob/main/code.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Z5Q3e793ayo"
      },
      "source": [
        "# Incubit Inc. Challenge Code, by Jorge J. Bennasar Vazquez"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sUeExaqvvzPm"
      },
      "source": [
        "# Import data from Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gMuH-IZb3vvw"
      },
      "source": [
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "import json\n",
        "import os\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np \n",
        "import copy\n",
        "import random\n",
        "\n",
        "from PIL import Image, ImageEnhance\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "annotations_path = 'drive/MyDrive/challenge/annotations'\n",
        "images_path = 'drive/MyDrive/challenge/raw'\n",
        "\n",
        "# Dataset class creation\n",
        "class my_dataset(torch.utils.data.Dataset):\n",
        "\n",
        "  def __init__(\n",
        "      self, \n",
        "      annotations_path,     # annotations path\n",
        "      images_path,          # images path\n",
        "      mode,                 # 'tr' for training, 'cv' for validation, 'tt' for testing\n",
        "      class_sel,            # 1 for 'Buildings', 2 for 'Houses' and 'Sheds/Garages', 3 for all classes\n",
        "      h_p = 0.5,            # probability of horizontal flip in data augmentation\n",
        "      v_p = 0.5,            # probability of vertical flip in data augmentation\n",
        "      c_p = 0.5,            # probability of cropping in data augmentation\n",
        "      window = [0.5, 1],    # window of lengths (in percentage) for cropping in data augmentation\n",
        "      factor = [0.9, 1.1],  # window of brightness factors in data augmentation\n",
        "      resize = 0.4,         # parameter to resize images (in percentage)\n",
        "      ):\n",
        "    \n",
        "    self.mode = mode\n",
        "    self.h_p = h_p\n",
        "    self.v_p = v_p\n",
        "    self.c_p = c_p\n",
        "    self.window = window\n",
        "    self.factor = factor\n",
        "    self.class_sel = class_sel\n",
        "    classes = ['Background', 'Buildings', 'Houses', 'Sheds/Garages']\n",
        "    self.classes = classes\n",
        "    self.resize = resize\n",
        "    EPS = 1-1e-8  # to assure resized polygons are within boundaries\n",
        "\n",
        "    # Select images for each set\n",
        "    if mode == 'tr':\n",
        "      i_sel = [0, 1, 2, 3, 4, 5, 6, 7]\n",
        "    elif mode == 'cv':\n",
        "      i_sel = [8]\n",
        "    else:\n",
        "      i_sel = [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
        "\n",
        "    # Get images, polygons and labels (only images for test set)\n",
        "    images = []\n",
        "    polygons = []\n",
        "    polygons_all = []\n",
        "    labels = []\n",
        "    labels_all = []\n",
        "\n",
        "    for i in i_sel:\n",
        "      for j in range(9):\n",
        "        image_ = Image.open(os.path.join(images_path, f'{i}_{j}.png')).convert('RGB')\n",
        "        image_shape = np.array(image_).shape\n",
        "        image_ = image_.resize((int(image_shape[1]*resize), int(image_shape[0]*resize)))  # image resizing\n",
        "        image_ = np.array(image_)\n",
        "        if os.path.isfile(os.path.join(annotations_path, f'{i}_{j}.png-annotated.json')):\n",
        "          if mode != 'tt':\n",
        "            polygons_ = []\n",
        "            polygons_all_ = []\n",
        "            labels_ = []\n",
        "            labels_all_ = []\n",
        "            with open(os.path.join(annotations_path, f'{i}_{j}.png-annotated.json'), 'r') as f:\n",
        "              data = json.load(f)\n",
        "            for k in range(len(data['labels'])):\n",
        "              label = data['labels'][k]['name']\n",
        "              for l in range(len(data['labels'][k]['annotations'])): \n",
        "                polygon = np.array(np.array(data['labels'][k]['annotations'][l]['segmentation']) * resize - EPS, dtype=int)  # polygon resizing\n",
        "                if class_sel == 1 and label == 'Buildings':\n",
        "                    polygons_.append(polygon)\n",
        "                    labels_.append(classes.index(label))\n",
        "                elif class_sel == 2 and label != 'Buildings':\n",
        "                    polygons_.append(polygon)\n",
        "                    labels_.append(classes.index(label) - 1)\n",
        "                elif class_sel == 3:\n",
        "                    polygons_.append(polygon)\n",
        "                    labels_.append(classes.index(label))\n",
        "                polygons_all_.append(polygon)\n",
        "                labels_all_.append(classes.index(label))\n",
        "            images.append(image_)\n",
        "            polygons.append(polygons_)\n",
        "            polygons_all.append(polygons_all_)\n",
        "            labels.append(labels_)\n",
        "            labels_all.append(labels_all_)\n",
        "        elif mode == 'tt':\n",
        "          images.append(image_)\n",
        "\n",
        "    self.images = images\n",
        "    self.polygons = polygons\n",
        "    self.polygons_all = polygons_all\n",
        "    self.labels = labels\n",
        "    self.labels_all = labels_all\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "\n",
        "    # Transform module creation\n",
        "    transform = transforms.Compose([\n",
        "        transforms.ToTensor(),  # convert to tensor\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),  # normalize\n",
        "    ])\n",
        "\n",
        "    if self.mode != 'tt':\n",
        "\n",
        "      # Calculate boxes from polygons\n",
        "      boxes = []\n",
        "      for i in range(len(self.polygons[idx])):\n",
        "        box = self.get_box(self.polygons[idx][i])\n",
        "        boxes.append(box)\n",
        "      boxes = np.array(boxes)\n",
        "\n",
        "      # Data loading and (if training) augmentation\n",
        "      if self.mode == 'tr':\n",
        "        image_, boxes_, polygons_, labels_ = self.augment(idx, boxes)\n",
        "      else:\n",
        "        image_ = self.images[idx]\n",
        "        boxes_ = boxes\n",
        "        polygons_ = self.polygons[idx]\n",
        "        labels_ = self.labels[idx]\n",
        "\n",
        "      # Calculate masks\n",
        "      masks_ = []\n",
        "      for i in range(len(polygons_)):\n",
        "        mask_ = self.get_mask(image_, polygons_[i])\n",
        "        masks_.append(mask_)\n",
        "\n",
        "      # To tensors\n",
        "      boxes_t = torch.tensor(boxes_, dtype=torch.float32)\n",
        "      labels_t = torch.tensor(labels_, dtype=torch.int64)\n",
        "      masks_t = torch.tensor(masks_, dtype=torch.uint8)\n",
        "      image_id_t = torch.tensor([idx])\n",
        "      area_t = (boxes_t[:, 3] - boxes_t[:, 1])*(boxes_t[:, 2] - boxes_t[:, 0])\n",
        "      iscrowd_t = torch.zeros((len(polygons_),), dtype=torch.int64)\n",
        "\n",
        "      target_ = {\n",
        "          'boxes': boxes_t,\n",
        "          'labels': labels_t,\n",
        "          'masks': masks_t,\n",
        "          'image_id': image_id_t,\n",
        "          'area': area_t,\n",
        "          'iscrowd': iscrowd_t,\n",
        "          }\n",
        "      image_ = Image.fromarray(image_)\n",
        "      return transform(image_), target_\n",
        "\n",
        "    else:\n",
        "\n",
        "      # Data loading\n",
        "      image_ = self.images[idx]\n",
        "\n",
        "      # To tensors\n",
        "      image_ = Image.fromarray(image_)\n",
        "      return transform(image_)\n",
        "\n",
        "  def __len__(self):\n",
        "\n",
        "    return len(self.images)\n",
        "\n",
        "  def get_box(self, polygon):\n",
        "\n",
        "    # Get individual box from polygon\n",
        "    xy_vec = polygon.reshape((-1, 2))\n",
        "    x_points = xy_vec[:, 0]\n",
        "    y_points = xy_vec[:, 1]\n",
        "    box = [min(x_points), min(y_points), max(x_points), max(y_points)]\n",
        "    \n",
        "    return box\n",
        "\n",
        "  def get_mask(self, image, polygon):\n",
        "\n",
        "    # Get individual mask\n",
        "    mask = np.zeros((image.shape[0], image.shape[1]), dtype=np.uint8)\n",
        "    xy_vec = polygon.reshape((-1, 2))\n",
        "    x_points = xy_vec[:, 0]\n",
        "    y_points = xy_vec[:, 1]\n",
        "    all_points = []\n",
        "    for j, x in enumerate(x_points):\n",
        "      all_points.append([x, y_points[j]])\n",
        "    all_points = np.array(all_points, dtype=int)\n",
        "    cv2.fillPoly(mask, [all_points], color=(1))\n",
        "    \n",
        "    return mask\n",
        "\n",
        "  def horizontal_flip(self, image, boxes, polygons, p):\n",
        "\n",
        "    # Apply horizontal flip with probability p\n",
        "    image_ = copy.copy(image)\n",
        "    boxes_ = np.array(copy.copy(boxes), dtype=float)\n",
        "    polygons_ = copy.deepcopy(polygons)\n",
        "\n",
        "    if random.random() < p:\n",
        "      image_center = np.array(image_.shape[:2])[::-1]/2\n",
        "      image_center = np.hstack((image_center, image_center))    \n",
        "      image_ =  image_[:,::-1,:]\n",
        "\n",
        "      boxes_[:,[0,2]] += 2*(image_center[[0,2]] - boxes_[:,[0,2]])\n",
        "      box_w = abs(boxes_[:,0] - boxes_[:,2])       \n",
        "      boxes_[:,0] -= box_w\n",
        "      boxes_[:,2] += box_w\n",
        "      boxes_ = np.array(boxes_, dtype=int)\n",
        "\n",
        "      for i in range(len(polygons_)):\n",
        "        polygons_[i][::2] = 2*image_center[0] - polygons_[i][::2]\n",
        "             \n",
        "    return image_, boxes_, polygons_\n",
        "\n",
        "  def vertical_flip(self, image, boxes, polygons, p):\n",
        "\n",
        "    # Apply vertical flip with probability p\n",
        "    image_ = copy.copy(image)\n",
        "    boxes_ = np.array(copy.copy(boxes), dtype=float)\n",
        "    polygons_ = copy.deepcopy(polygons)\n",
        "\n",
        "    if random.random() < p:\n",
        "      image_center = np.array(image_.shape[:2])[::-1]/2\n",
        "      image_center = np.hstack((image_center, image_center))    \n",
        "      image_ =  image_[::-1,:,:]\n",
        "\n",
        "      boxes_[:,[1,3]] += 2*(image_center[[1,3]] - boxes_[:,[1,3]])\n",
        "      box_w = abs(boxes_[:,1] - boxes_[:,3])       \n",
        "      boxes_[:,1] -= box_w\n",
        "      boxes_[:,3] += box_w\n",
        "      boxes_ = np.array(boxes_, dtype=int)\n",
        "\n",
        "      for i in range(len(polygons_)):\n",
        "        polygons_[i][1::2] = 2*image_center[1] - polygons_[i][1::2]\n",
        "              \n",
        "    return image_, boxes_, polygons_\n",
        "\n",
        "  def crop(self, image, boxes, polygons, labels, p, window):\n",
        "\n",
        "    # Crop images within a window of lengths with probability p\n",
        "    if random.random() < p: \n",
        "\n",
        "      flag = False\n",
        "      while flag is False:\n",
        "        image_ = copy.copy(image)\n",
        "        boxes_ = copy.copy(boxes)\n",
        "        polygons_ = copy.deepcopy(polygons)\n",
        "      \n",
        "        len_x = random.randint(int(image_.shape[1]*window[0]), int(image_.shape[1]*window[1]))\n",
        "        len_y = random.randint(int(image_.shape[0]*window[0]), int(image_.shape[0]*window[1]))\n",
        "        x_1 = random.randint(0, int(image_.shape[1]-len_x))\n",
        "        x_2 = int(x_1+len_x)\n",
        "        y_1 = random.randint(0, int(image_.shape[0]-len_y))\n",
        "        y_2 = int(y_1+len_y)\n",
        "\n",
        "        image_crop = image_[y_1:y_2, x_1:x_2, :]\n",
        "        boxes_crop = []\n",
        "        polygons_crop = []\n",
        "        labels_crop = []\n",
        "        for i in range(len(polygons_)):\n",
        "          x_aux_max = max(polygons_[i][::2])\n",
        "          y_aux_max = max(polygons_[i][1::2])\n",
        "          x_aux_min = min(polygons_[i][::2])\n",
        "          y_aux_min = min(polygons_[i][1::2])\n",
        "          if x_aux_max < x_2 and x_aux_min > x_1 and y_aux_max < y_2 and y_aux_min > y_1:\n",
        "            polygons_[i][::2] -= x_1\n",
        "            polygons_[i][1::2] -= y_1\n",
        "            polygons_crop.append(polygons_[i])\n",
        "            xy_vec = polygons_crop[-1].reshape((-1, 2))\n",
        "            x_points = xy_vec[:, 0]\n",
        "            y_points = xy_vec[:, 1]\n",
        "            boxes_crop.append([min(x_points), min(y_points), max(x_points), \n",
        "                              max(y_points)])\n",
        "            labels_crop.append(labels[i])\n",
        "            \n",
        "        if len(boxes_crop) > 0:\n",
        "          boxes_crop = np.array(boxes_crop)\n",
        "          flag = True\n",
        "\n",
        "      return image_crop, boxes_crop, polygons_crop, labels_crop\n",
        "\n",
        "    else:\n",
        "\n",
        "      return image, boxes, polygons, labels\n",
        "\n",
        "  def brightness_change(self, image, factor):\n",
        "\n",
        "    # Change the brightness of the image\n",
        "    image_ = Image.fromarray(copy.copy(image)).convert('RGB')\n",
        "    enhancer = ImageEnhance.Brightness(image_)\n",
        "    f = factor[0] + (factor[1]-factor[0])*np.random.rand()\n",
        "    image_ = enhancer.enhance(f)\n",
        "\n",
        "    return np.array(image_)\n",
        "\n",
        "  def augment(self, idx, boxes):\n",
        "    \n",
        "    # Data augmentation (horizontal and vertical flips, cropping and brightness)\n",
        "    image_v, boxes_v, polygons_v = self.vertical_flip(\n",
        "        self.images[idx], boxes, self.polygons[idx], self.v_p)\n",
        "    image_vh, boxes_vh, polygons_vh = self.horizontal_flip(\n",
        "        image_v, boxes_v, polygons_v, self.h_p)\n",
        "    image_vhc, boxes_vhc, polygons_vhc, labels_vhc = self.crop(\n",
        "        image_vh, boxes_vh, polygons_vh, self.labels[idx], \n",
        "        self.c_p, self.window)\n",
        "    image_vhcb = self.brightness_change(image_vhc, self.factor)\n",
        "\n",
        "    return image_vhcb, boxes_vhc, polygons_vhc, labels_vhc\n",
        "\n",
        "  def plot_mask(self, idx):\n",
        "\n",
        "    # Plot image mask\n",
        "    mask = np.ones((self.images[idx].shape[0], self.images[idx].shape[1], 3), dtype=np.float32) * 0.75\n",
        "    for i in range(len(self.polygons_all[idx])):\n",
        "      mask_ = np.squeeze(self.get_mask(self.images[idx], self.polygons_all[idx][i]))\n",
        "      dim = [1, 2, 0]\n",
        "      for j in range(3):\n",
        "        mask[:, :, j] -= mask_ * 0.75 \n",
        "      mask[:, :, dim[self.labels_all[idx][i]-1]] += mask_ \n",
        "    plt.imshow(mask)\n",
        "\n",
        "  def plot_boxes(self, idx):\n",
        "\n",
        "    # Plot image with boxes\n",
        "    plt.imshow(self.images[idx])\n",
        "    for i in range(len(self.polygons_all[idx])):\n",
        "      box = self.get_box(self.polygons_all[idx][i])\n",
        "      xy_vec = np.array(box).reshape((-1, 2))\n",
        "      x_vec = np.array([xy_vec[0, 0], xy_vec[0, 0], xy_vec[1, 0], xy_vec[1, 0], xy_vec[0, 0]])\n",
        "      y_vec = np.array([xy_vec[0, 1], xy_vec[1, 1], xy_vec[1, 1], xy_vec[0, 1], xy_vec[0, 1]])\n",
        "      if self.labels_all[idx][i] == 1:\n",
        "        color = 'lightgreen'\n",
        "      elif self.labels_all[idx][i] == 2:\n",
        "        color = 'blue'\n",
        "      else:\n",
        "        color = 'orangered'\n",
        "      plt.plot(x_vec, y_vec, color=color)\n",
        "        \n",
        "  def plot_polygons(self, idx):\n",
        "\n",
        "    # Plot image with polygons\n",
        "    plt.imshow(self.images[idx])\n",
        "    for i in range(len(self.polygons_all[idx])):\n",
        "      xy_vec = np.array(self.polygons_all[idx][i]).reshape((-1, 2))\n",
        "      x_vec = np.concatenate((xy_vec[:, 0], xy_vec[0, 0]), axis=None)\n",
        "      y_vec = np.concatenate((xy_vec[:, 1], xy_vec[0, 1]), axis=None)\n",
        "      if self.labels_all[idx][i] == 1:\n",
        "        color = 'lightgreen'\n",
        "      elif self.labels_all[idx][i] == 2:\n",
        "        color = 'blue'\n",
        "      else:\n",
        "        color = 'orangered'\n",
        "      plt.plot(x_vec, y_vec, color=color)\n",
        "\n",
        "  def get_data(self, idx):\n",
        "\n",
        "    # Get data dictionary from self\n",
        "    image = self.images[idx]\n",
        "    if self.mode != 'tt':\n",
        "      polygons = self.polygons_all[idx]\n",
        "      labels = self.labels_all[idx]\n",
        "\n",
        "      # Calculate boxes\n",
        "      boxes = []\n",
        "      for i in range(len(polygons)):\n",
        "        box = self.get_box(polygons[i])\n",
        "        boxes.append(box)\n",
        "      boxes = np.array(boxes)\n",
        "\n",
        "      # Calculate mask\n",
        "      mask = np.zeros((image.shape[0], image.shape[1], 3), dtype=np.uint8)\n",
        "      for i in range(len(polygons)):\n",
        "        xy_vec = polygons[i].reshape((-1, 2))\n",
        "        x_points = xy_vec[:, 0]\n",
        "        y_points = xy_vec[:, 1]\n",
        "        all_points = []\n",
        "        for j, x in enumerate(x_points):\n",
        "          all_points.append([x, y_points[j]])\n",
        "        all_points = np.array(all_points, dtype=int)\n",
        "        if labels[i] == 1:\n",
        "          color = (0, 255, 0)\n",
        "        elif labels[i] == 2:\n",
        "          color = (0, 0, 255)\n",
        "        else:\n",
        "          color = (255, 0, 0)\n",
        "        cv2.fillPoly(mask, [all_points], color=color)\n",
        "      \n",
        "      data = {\n",
        "          'image': image,\n",
        "          'polygons': polygons,\n",
        "          'boxes': boxes,\n",
        "          'labels': labels,\n",
        "          'mask': mask,\n",
        "      }\n",
        "    else:\n",
        "      data = {\n",
        "          'image': image\n",
        "      }\n",
        "    \n",
        "    return data\n",
        "\n",
        "  def get_areas(self):\n",
        "\n",
        "    # Get areas (in pixels) for the different classes\n",
        "    areas = {\n",
        "        'Buildings': [],\n",
        "        'Houses': [],\n",
        "        'Sheds/Garages': [],\n",
        "    }\n",
        "    for i in range(len(self.images)):\n",
        "      for j in range(len(self.labels_all[i])):\n",
        "        areas[self.classes[self.labels_all[i][j]]].append(np.sum(np.array(self.get_mask(self.images[i], self.polygons_all[i][j]))))\n",
        "\n",
        "    return areas"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vRmIZvZjR-yQ"
      },
      "source": [
        "# Create train dataset (Buildings)\n",
        "train_dataset_1 = my_dataset(\n",
        "      annotations_path, \n",
        "      images_path, \n",
        "      mode='tr',\n",
        "      class_sel=1,\n",
        "      )\n",
        "\n",
        "# Create validation dataset (Buildings)\n",
        "val_dataset_1 = my_dataset(\n",
        "      annotations_path, \n",
        "      images_path, \n",
        "      mode='cv',\n",
        "      class_sel=1,\n",
        "      )\n",
        "\n",
        "# Create train dataset (Houses and Sheds/Garages)\n",
        "train_dataset_2 = my_dataset(\n",
        "      annotations_path, \n",
        "      images_path, \n",
        "      mode='tr',\n",
        "      class_sel=2,\n",
        "      )\n",
        "\n",
        "# Create validation dataset (Houses and Sheds/Garages)\n",
        "val_dataset_2 = my_dataset(\n",
        "      annotations_path, \n",
        "      images_path, \n",
        "      mode='cv',\n",
        "      class_sel=2,\n",
        "      )"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wR1tRGzC4bFo"
      },
      "source": [
        "# Get statistics for training data\n",
        "areas = train_dataset_1.get_areas()\n",
        "mean_area_buildings = np.mean(np.array(areas['Buildings']))\n",
        "mean_area_houses = np.mean(np.array(areas['Houses']))\n",
        "mean_area_sheds_and_garages = np.mean(np.array(areas['Sheds/Garages']))\n",
        "std_area_buildings = np.std(np.array(areas['Buildings']))\n",
        "std_area_houses = np.std(np.array(areas['Houses']))\n",
        "std_area_sheds_and_garages = np.std(np.array(areas['Sheds/Garages']))\n",
        "num_samples_buildings = len(areas['Buildings'])\n",
        "num_samples_houses = len(areas['Houses'])\n",
        "num_samples_sheds_and_garages = len(areas['Sheds/Garages'])\n",
        "\n",
        "print('Mean of areas:  Buildings:', str(mean_area_buildings), ' Houses:', str(mean_area_houses), ' Sheds/Garages:', str(mean_area_sheds_and_garages))\n",
        "print('Standard deviation of areas:  Buildings:', str(std_area_buildings), ' Houses:', str(std_area_houses), ' Sheds/Garages:', str(std_area_sheds_and_garages))\n",
        "print('Number of samples:  Buildings:', str(num_samples_buildings), ' Houses:', str(num_samples_houses), ' Sheds/Garages:', str(num_samples_sheds_and_garages))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tDRbma0aBtWK"
      },
      "source": [
        "# Plot histogram\n",
        "import seaborn\n",
        "\n",
        "# Function to remove outliers (for class 'Buildings' only, to improve visualization)\n",
        "def remove_outliers(data, q1_pos, q2_pos):\n",
        "\n",
        "  # Function to remove outliers\n",
        "  q1 = np.quantile(data, q1_pos)\n",
        "  q2 = np.quantile(data, q2_pos)\n",
        "  data_clean = []\n",
        "  for i in range(len(data)):\n",
        "    if data[i] >= q1 and data[i] <= q2:\n",
        "      data_clean.append(data[i])\n",
        "\n",
        "  return data_clean\n",
        "\n",
        "plt.figure()\n",
        "seaborn.histplot(data=np.array(remove_outliers(areas['Buildings'], 0, 0.8)), stat='count', kde=True, binwidth=10, color='lightgreen', fill=False)\n",
        "seaborn.histplot(data=np.array(areas['Houses']), stat='count', kde=True, binwidth=10, color='blue', fill=False)\n",
        "seaborn.histplot(data=np.array(areas['Sheds/Garages']), stat='count', kde=True, binwidth=10, color='orangered', fill=False)\n",
        "plt.xlim([0, max(remove_outliers(areas['Buildings'], 0, 0.8))])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ws3s1DOeSXVG"
      },
      "source": [
        "# Create train and validation dataloaders\n",
        "batch_size_tr = 4\n",
        "batch_size_cv = 6  # Do not change, important to store all validation loss metrics\n",
        "num_workers = 1\n",
        "\n",
        "def collate_fn(batch):\n",
        "  return tuple(zip(*batch))\n",
        "\n",
        "train_loader_1 = torch.utils.data.DataLoader(\n",
        "    train_dataset_1, \n",
        "    batch_size=batch_size_tr,\n",
        "    shuffle=True,\n",
        "    drop_last=True,\n",
        "    num_workers=num_workers,\n",
        "    collate_fn=collate_fn,\n",
        "    )\n",
        "\n",
        "val_loader_1 = torch.utils.data.DataLoader(\n",
        "    val_dataset_1, \n",
        "    batch_size=batch_size_cv,\n",
        "    shuffle=True,\n",
        "    drop_last=True,\n",
        "    num_workers=num_workers,\n",
        "    collate_fn=collate_fn,\n",
        "    )\n",
        "\n",
        "train_loader_2 = torch.utils.data.DataLoader(\n",
        "    train_dataset_2, \n",
        "    batch_size=batch_size_tr,\n",
        "    shuffle=True,\n",
        "    drop_last=True,\n",
        "    num_workers=num_workers,\n",
        "    collate_fn=collate_fn,\n",
        "    )\n",
        "\n",
        "val_loader_2 = torch.utils.data.DataLoader(\n",
        "    val_dataset_2, \n",
        "    batch_size=batch_size_cv,\n",
        "    shuffle=True,\n",
        "    drop_last=True,\n",
        "    num_workers=num_workers,\n",
        "    collate_fn=collate_fn,\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hBnf923ZQtYa"
      },
      "source": [
        "# Clone PyTorch Vision\n",
        "! git clone 'https://github.com/pytorch/vision'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hDz92DT5RD0a"
      },
      "source": [
        "# Engine for training (based on: 'https://github.com/pytorch/vision/blob/master/references/detection/engine.py')\n",
        "import math\n",
        "import sys\n",
        "import time\n",
        "import vision.references.detection.utils as utils\n",
        "\n",
        "def train_one_epoch(model, optimizer, data_loader, device, epoch, print_freq):\n",
        "  model.train()\n",
        "  metric_logger = utils.MetricLogger(delimiter=\"  \")\n",
        "  metric_logger.add_meter('lr', utils.SmoothedValue(window_size=1, fmt='{value:.6f}'))\n",
        "  header = 'Epoch: [{}]'.format(epoch)\n",
        "\n",
        "  lr_scheduler = None\n",
        "  if epoch == 0:\n",
        "    warmup_factor = 1. / 1000\n",
        "    warmup_iters = min(1000, len(data_loader) - 1)\n",
        "    lr_scheduler = utils.warmup_lr_scheduler(optimizer, warmup_iters, warmup_factor)\n",
        "\n",
        "  for images, targets in metric_logger.log_every(data_loader, print_freq, header):\n",
        "    images = list(image.to(device) for image in images)\n",
        "    targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
        "    loss_dict = model(images, targets)\n",
        "    losses = sum(loss for loss in loss_dict.values())\n",
        "    loss_dict_reduced = utils.reduce_dict(loss_dict)\n",
        "    losses_reduced = sum(loss for loss in loss_dict_reduced.values())\n",
        "    loss_value = losses_reduced.item()\n",
        "\n",
        "    if not math.isfinite(loss_value):\n",
        "      print(\"Loss is {}, stopping training\".format(loss_value))\n",
        "      print(loss_dict_reduced)\n",
        "      sys.exit(1)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    losses.backward()\n",
        "    optimizer.step()\n",
        "    if lr_scheduler is not None:\n",
        "      lr_scheduler.step()\n",
        "    metric_logger.update(loss=losses_reduced, **loss_dict_reduced)\n",
        "    metric_logger.update(lr=optimizer.param_groups[0][\"lr\"])\n",
        "\n",
        "  return metric_logger"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q8JSJQz2nWEL"
      },
      "source": [
        "# Model creation and hyper-parameter selection\n",
        "import torchvision\n",
        "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
        "from torchvision.models.detection.mask_rcnn import MaskRCNNPredictor\n",
        "\n",
        "# Create models\n",
        "num_classes_1 = 2\n",
        "hidden_layer_1 = 512 \n",
        "model_1 = torchvision.models.detection.maskrcnn_resnet50_fpn(pretrained=True)\n",
        "in_features_1 = model_1.roi_heads.box_predictor.cls_score.in_features\n",
        "model_1.roi_heads.box_predictor = FastRCNNPredictor(in_features_1, num_classes_1)\n",
        "in_features_mask_1 = model_1.roi_heads.mask_predictor.conv5_mask.in_channels\n",
        "model_1.roi_heads.mask_predictor = MaskRCNNPredictor(in_features_mask_1, hidden_layer_1, num_classes_1)\n",
        "\n",
        "num_classes_2 = 3\n",
        "hidden_layer_2 = 512 \n",
        "model_2 = torchvision.models.detection.maskrcnn_resnet50_fpn(pretrained=True)\n",
        "in_features_2 = model_2.roi_heads.box_predictor.cls_score.in_features\n",
        "model_2.roi_heads.box_predictor = FastRCNNPredictor(in_features_2, num_classes_2)\n",
        "in_features_mask_2 = model_2.roi_heads.mask_predictor.conv5_mask.in_channels\n",
        "model_2.roi_heads.mask_predictor = MaskRCNNPredictor(in_features_mask_2, hidden_layer_2, num_classes_2)\n",
        "\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "\n",
        "# Define optimizers\n",
        "lr_1 = 1e-03\n",
        "weight_decay_1 = 0.0005\n",
        "betas_1 = (0.9, 0.999)\n",
        "eps_1 = 1e-08\n",
        "params_1 = [p for p in model_1.parameters() if p.requires_grad]\n",
        "optimizer_1 = torch.optim.Adam(params_1, lr=lr_1, betas=betas_1, eps=eps_1, weight_decay=weight_decay_1, amsgrad=False)\n",
        "\n",
        "lr_2 = 1e-03\n",
        "weight_decay_2 = 0.0005\n",
        "betas_2 = (0.9, 0.999)\n",
        "eps_2 = 1e-08\n",
        "params_2 = [p for p in model_2.parameters() if p.requires_grad]\n",
        "optimizer_2 = torch.optim.Adam(params_2, lr=lr_2, betas=betas_2, eps=eps_2, weight_decay=weight_decay_2, amsgrad=False)\n",
        "\n",
        "# Define learning rate schedulers\n",
        "step_size_1 = 2  \n",
        "gamma_1 = 0.9 \n",
        "lr_scheduler_1 = torch.optim.lr_scheduler.StepLR(optimizer_1, step_size=step_size_1, gamma=gamma_1)\n",
        "\n",
        "step_size_2 = 2  \n",
        "gamma_2 = 0.9 \n",
        "lr_scheduler_2 = torch.optim.lr_scheduler.StepLR(optimizer_2, step_size=step_size_2, gamma=gamma_2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GPFVN5FFENpg"
      },
      "source": [
        "# Training\n",
        "num_epochs_1 = 40\n",
        "num_epochs_2 = 40\n",
        "\n",
        "# Function to save loss metrics\n",
        "def append_losses(loss_dict, logger):\n",
        "  loss_dict['loss'].append(sum(train_logger.__getattr__('loss').deque)/\n",
        "                           len(train_logger.__getattr__('loss').deque))  \n",
        "  loss_dict['loss_classifier'].append(sum(train_logger.__getattr__('loss_classifier').deque)/\n",
        "                                      len(train_logger.__getattr__('loss_classifier').deque)) \n",
        "  loss_dict['loss_box_reg'].append(sum(train_logger.__getattr__('loss_box_reg').deque)/\n",
        "                                   len(train_logger.__getattr__('loss_box_reg').deque))  \n",
        "  loss_dict['loss_mask'].append(sum(train_logger.__getattr__('loss_mask').deque)/\n",
        "                                len(train_logger.__getattr__('loss_mask').deque))  \n",
        "  loss_dict['loss_objectness'].append(sum(train_logger.__getattr__('loss_objectness').deque)/\n",
        "                                      len(train_logger.__getattr__('loss_objectness').deque))  \n",
        "  loss_dict['loss_rpn_box_reg'].append(sum(train_logger.__getattr__('loss_rpn_box_reg').deque)/\n",
        "                                       len(train_logger.__getattr__('loss_rpn_box_reg').deque))  \n",
        "\n",
        "  return loss_dict\n",
        "\n",
        "loss_tr_1 = {\n",
        "    'loss': [],\n",
        "    'loss_classifier': [],\n",
        "    'loss_box_reg': [],\n",
        "    'loss_mask': [],\n",
        "    'loss_objectness': [],\n",
        "    'loss_rpn_box_reg': [],\n",
        "}\n",
        "\n",
        "loss_cv_1 = {\n",
        "    'loss': [],\n",
        "    'loss_classifier': [],\n",
        "    'loss_box_reg': [],\n",
        "    'loss_mask': [],\n",
        "    'loss_objectness': [],\n",
        "    'loss_rpn_box_reg': [],\n",
        "}\n",
        "\n",
        "loss_tr_2 = {\n",
        "    'loss': [],\n",
        "    'loss_classifier': [],\n",
        "    'loss_box_reg': [],\n",
        "    'loss_mask': [],\n",
        "    'loss_objectness': [],\n",
        "    'loss_rpn_box_reg': [],\n",
        "}\n",
        "\n",
        "loss_cv_2 = {\n",
        "    'loss': [],\n",
        "    'loss_classifier': [],\n",
        "    'loss_box_reg': [],\n",
        "    'loss_mask': [],\n",
        "    'loss_objectness': [],\n",
        "    'loss_rpn_box_reg': [],\n",
        "}\n",
        "\n",
        "print('')\n",
        "print('==================================================')\n",
        "print('')\n",
        "print('------------------ M O D E L - 1 -----------------')\n",
        "print('')\n",
        "print('==================================================')\n",
        "print('')\n",
        "\n",
        "model_1.train()\n",
        "for epoch in range(num_epochs_1):\n",
        "\n",
        "  # Training\n",
        "  model_1.to(device)\n",
        "  train_logger = train_one_epoch(model_1, optimizer_1, train_loader_1, device, epoch, print_freq=4)\n",
        "  lr_scheduler_1.step()\n",
        "\n",
        "  # Saving training loss metrics\n",
        "  loss_tr_1 = append_losses(loss_tr_1, train_logger)\n",
        " \n",
        "  # Validation\n",
        "  with torch.no_grad():\n",
        "    cpu_device = torch.device(\"cpu\")\n",
        "    model_1.to(cpu_device)\n",
        "    for batch_idx, (images, targets) in enumerate(val_loader_1):\n",
        "      val_logger = model_1(images, targets)\n",
        "    \n",
        "  # Saving validation loss metrics\n",
        "  loss_cv_1['loss_classifier'].append(float(val_logger['loss_classifier'].cpu().detach().numpy()))\n",
        "  loss_cv_1['loss_box_reg'].append(float(val_logger['loss_box_reg'].cpu().detach().numpy()))\n",
        "  loss_cv_1['loss_mask'].append(float(val_logger['loss_mask'].cpu().detach().numpy()))\n",
        "  loss_cv_1['loss_objectness'].append(float(val_logger['loss_objectness'].cpu().detach().numpy()))\n",
        "  loss_cv_1['loss_rpn_box_reg'].append(float(val_logger['loss_rpn_box_reg'].cpu().detach().numpy()))\n",
        "  loss_cv_1['loss'].append(float(loss_cv_1['loss_classifier'][-1] + loss_cv_1['loss_box_reg'][-1] +\n",
        "                                 loss_cv_1['loss_mask'][-1] + loss_cv_1['loss_objectness'][-1] + \n",
        "                                 loss_cv_1['loss_rpn_box_reg'][-1]))\n",
        "\n",
        "  print('')\n",
        "  print('==================================================')\n",
        "  print('')\n",
        "\n",
        "  print('Training results:  loss:', str(loss_tr_1['loss'][-1]), \n",
        "        ' loss_classifier:', str(loss_tr_1['loss_classifier'][-1]), \n",
        "        ' loss_box_reg:', str(loss_tr_1['loss_box_reg'][-1]), \n",
        "        ' loss_mask:', str(loss_tr_1['loss_mask'][-1]),\n",
        "        ' loss_objectness:', str(loss_tr_1['loss_objectness'][-1]),\n",
        "        ' loss_rpn_box_reg:', str(loss_tr_1['loss_rpn_box_reg'][-1]))\n",
        "  \n",
        "  print('')\n",
        "  print('==================================================')\n",
        "  print('')\n",
        "\n",
        "  print('Validation results:  loss:', str(loss_cv_1['loss'][-1]), \n",
        "        ' loss_classifier:', str(loss_cv_1['loss_classifier'][-1]), \n",
        "        ' loss_box_reg:', str(loss_cv_1['loss_box_reg'][-1]), \n",
        "        ' loss_mask:', str(loss_cv_1['loss_mask'][-1]),\n",
        "        ' loss_objectness:', str(loss_cv_1['loss_objectness'][-1]),\n",
        "        ' loss_rpn_box_reg:', str(loss_cv_1['loss_rpn_box_reg'][-1]))\n",
        "    \n",
        "  print('')\n",
        "  print('==================================================')\n",
        "  print('')\n",
        "\n",
        "print('')\n",
        "print('==================================================')\n",
        "print('')\n",
        "print('------------------ M O D E L - 2 -----------------')\n",
        "print('')\n",
        "print('==================================================')\n",
        "print('')\n",
        "\n",
        "model_2.train()\n",
        "for epoch in range(num_epochs_2):\n",
        "\n",
        "  # Training\n",
        "  model_2.to(device)\n",
        "  train_logger = train_one_epoch(model_2, optimizer_2, train_loader_2, device, epoch, print_freq=2)\n",
        "  lr_scheduler_2.step()\n",
        "\n",
        "  # Saving training loss metrics\n",
        "  loss_tr_2 = append_losses(loss_tr_2, train_logger)\n",
        " \n",
        "  # Validation\n",
        "  with torch.no_grad():\n",
        "    cpu_device = torch.device(\"cpu\")\n",
        "    model_2.to(cpu_device)\n",
        "    for batch_idx, (images, targets) in enumerate(val_loader_2):\n",
        "      val_logger = model_2(images, targets)\n",
        "    \n",
        "  # Saving validation loss metrics\n",
        "  loss_cv_2['loss_classifier'].append(float(val_logger['loss_classifier'].cpu().detach().numpy()))\n",
        "  loss_cv_2['loss_box_reg'].append(float(val_logger['loss_box_reg'].cpu().detach().numpy()))\n",
        "  loss_cv_2['loss_mask'].append(float(val_logger['loss_mask'].cpu().detach().numpy()))\n",
        "  loss_cv_2['loss_objectness'].append(float(val_logger['loss_objectness'].cpu().detach().numpy()))\n",
        "  loss_cv_2['loss_rpn_box_reg'].append(float(val_logger['loss_rpn_box_reg'].cpu().detach().numpy()))\n",
        "  loss_cv_2['loss'].append(float(loss_cv_2['loss_classifier'][-1] + loss_cv_2['loss_box_reg'][-1] +\n",
        "                                 loss_cv_2['loss_mask'][-1] + loss_cv_2['loss_objectness'][-1] + \n",
        "                                 loss_cv_2['loss_rpn_box_reg'][-1]))\n",
        "\n",
        "  print('')\n",
        "  print('==================================================')\n",
        "  print('')\n",
        "\n",
        "  print('Training results:  loss:', str(loss_tr_2['loss'][-1]), \n",
        "        ' loss_classifier:', str(loss_tr_2['loss_classifier'][-1]), \n",
        "        ' loss_box_reg:', str(loss_tr_2['loss_box_reg'][-1]), \n",
        "        ' loss_mask:', str(loss_tr_2['loss_mask'][-1]),\n",
        "        ' loss_objectness:', str(loss_tr_2['loss_objectness'][-1]),\n",
        "        ' loss_rpn_box_reg:', str(loss_tr_2['loss_rpn_box_reg'][-1]))\n",
        "  \n",
        "  print('')\n",
        "  print('==================================================')\n",
        "  print('')\n",
        "\n",
        "  print('Validation results:  loss:', str(loss_cv_2['loss'][-1]), \n",
        "        ' loss_classifier:', str(loss_cv_2['loss_classifier'][-1]), \n",
        "        ' loss_box_reg:', str(loss_cv_2['loss_box_reg'][-1]), \n",
        "        ' loss_mask:', str(loss_cv_2['loss_mask'][-1]),\n",
        "        ' loss_objectness:', str(loss_cv_2['loss_objectness'][-1]),\n",
        "        ' loss_rpn_box_reg:', str(loss_cv_2['loss_rpn_box_reg'][-1]))\n",
        "    \n",
        "  print('')\n",
        "  print('==================================================')\n",
        "  print('')\n",
        "\n",
        "print(\"C'est fini!\")\n",
        "\n",
        "# Saving models\n",
        "model_1_name = 'model_buildings'\n",
        "save_path_1 = '/content/drive/MyDrive/Colab Notebooks/' + model_1_name + '.pth'\n",
        "torch.save(model_1.state_dict(), save_path_1)\n",
        "with open('/content/drive/MyDrive/Colab Notebooks/' + model_1_name + '_loss_tr.json', 'w') as f:\n",
        "  json.dump(loss_tr_1, f)\n",
        "with open('/content/drive/MyDrive/Colab Notebooks/' + model_1_name + '_loss_cv.json', 'w') as f:\n",
        "  json.dump(loss_cv_1, f)\n",
        "\n",
        "model_2_name = 'model_houses_sheds_and_garages'\n",
        "save_path_2 = '/content/drive/MyDrive/Colab Notebooks/' + model_2_name + '.pth'\n",
        "torch.save(model_2.state_dict(), save_path_2)\n",
        "with open('/content/drive/MyDrive/Colab Notebooks/' + model_2_name + '_loss_tr.json', 'w') as f:\n",
        "  json.dump(loss_tr_2, f)\n",
        "with open('/content/drive/MyDrive/Colab Notebooks/' + model_2_name + '_loss_cv.json', 'w') as f:\n",
        "  json.dump(loss_cv_2, f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GfJ2DBpjixi_"
      },
      "source": [
        "# Loading models\n",
        "model_1_name = 'model_buildings'\n",
        "model_2_name = 'model_houses_sheds_and_garages'\n",
        "\n",
        "model_1.load_state_dict(torch.load('/content/drive/MyDrive/Colab Notebooks/' + model_1_name + '.pth'))\n",
        "with open('/content/drive/MyDrive/Colab Notebooks/' + model_1_name + '_loss_tr.json', 'r') as f:\n",
        "  loss_tr_1 = json.load(f)\n",
        "with open('/content/drive/MyDrive/Colab Notebooks/' + model_1_name + '_loss_cv.json', 'r') as f:\n",
        "  loss_cv_1 = json.load(f)\n",
        "\n",
        "model_2.load_state_dict(torch.load('/content/drive/MyDrive/Colab Notebooks/' + model_2_name + '.pth'))\n",
        "with open('/content/drive/MyDrive/Colab Notebooks/' + model_2_name + '_loss_tr.json', 'r') as f:\n",
        "  loss_tr_2 = json.load(f)\n",
        "with open('/content/drive/MyDrive/Colab Notebooks/' + model_2_name + '_loss_cv.json', 'r') as f:\n",
        "  loss_cv_2 = json.load(f)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "69EcAiAwj4Vp"
      },
      "source": [
        "# Loss plots for training and validation\n",
        "x_tr_1 = [i for i in range(len(loss_tr_1['loss']))]\n",
        "x_cv_1 = [i for i in range(len(loss_cv_1['loss']))]\n",
        "x_tr_2 = [i for i in range(len(loss_tr_2['loss']))]\n",
        "x_cv_2 = [i for i in range(len(loss_cv_2['loss']))]\n",
        "\n",
        "plt.figure(figsize=(30, 10))\n",
        "\n",
        "plt.subplot(2, 6, 1)\n",
        "plt.plot(x_tr_1, loss_tr_1['loss'], color='lightgreen', linewidth=8)\n",
        "plt.plot(x_cv_1, loss_cv_1['loss'], color='blue', linewidth=8)\n",
        "plt.ylabel(\"Loss (Model 1)\")\n",
        "plt.title(\"Total Loss\")\n",
        "plt.ylim([1, 3])\n",
        "\n",
        "plt.subplot(2, 6, 2)\n",
        "plt.plot(x_tr_1, loss_tr_1['loss_classifier'], color='lightgreen', linewidth=8)\n",
        "plt.plot(x_cv_1, loss_cv_1['loss_classifier'], color='blue', linewidth=8)\n",
        "plt.title(\"Classifier Loss\")\n",
        "plt.ylim([0.2, 0.7])\n",
        "\n",
        "plt.subplot(2, 6, 3)\n",
        "plt.plot(x_tr_1, loss_tr_1['loss_box_reg'], color='lightgreen', linewidth=8)\n",
        "plt.plot(x_cv_1, loss_cv_1['loss_box_reg'], color='blue', linewidth=8)\n",
        "plt.title(\"Box Reg. Loss\")\n",
        "plt.ylim([0.3, 0.8])\n",
        "\n",
        "plt.subplot(2, 6, 4)\n",
        "plt.plot(x_tr_1, loss_tr_1['loss_mask'], color='lightgreen', linewidth=8)\n",
        "plt.plot(x_cv_1, loss_cv_1['loss_mask'], color='blue', linewidth=8)\n",
        "plt.title(\"Mask Loss\")\n",
        "plt.ylim([0.2, 0.9])\n",
        "\n",
        "plt.subplot(2, 6, 5)\n",
        "plt.plot(x_tr_1, loss_tr_1['loss_objectness'], color='lightgreen', linewidth=8)\n",
        "plt.plot(x_cv_1, loss_cv_1['loss_objectness'], color='blue', linewidth=8)\n",
        "plt.title(\"Objectness Loss\")\n",
        "plt.ylim([0, 0.7])\n",
        "\n",
        "plt.subplot(2, 6, 6)\n",
        "plt.plot(x_tr_1, loss_tr_1['loss_rpn_box_reg'], color='lightgreen', linewidth=8)\n",
        "plt.plot(x_cv_1, loss_cv_1['loss_rpn_box_reg'], color='blue', linewidth=8)\n",
        "plt.title(\"RPN Box Reg. Loss\")\n",
        "plt.ylim([0, 0.3])\n",
        "\n",
        "plt.subplot(2, 6, 7)\n",
        "plt.plot(x_tr_2, loss_tr_2['loss'], color='lightgreen', linewidth=8)\n",
        "plt.plot(x_cv_2, loss_cv_2['loss'], color='blue', linewidth=8)\n",
        "plt.ylabel(\"Loss (Model 2)\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylim([1, 3])\n",
        "\n",
        "plt.subplot(2, 6, 8)\n",
        "plt.plot(x_tr_2, loss_tr_2['loss_classifier'], color='lightgreen', linewidth=8)\n",
        "plt.plot(x_cv_2, loss_cv_2['loss_classifier'], color='blue', linewidth=8)\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylim([0.2, 0.7])\n",
        "\n",
        "plt.subplot(2, 6, 9)\n",
        "plt.plot(x_tr_2, loss_tr_2['loss_box_reg'], color='lightgreen', linewidth=8)\n",
        "plt.plot(x_cv_2, loss_cv_2['loss_box_reg'], color='blue', linewidth=8)\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylim([0.3, 0.8])\n",
        "\n",
        "plt.subplot(2, 6, 10)\n",
        "plt.plot(x_tr_2, loss_tr_2['loss_mask'], color='lightgreen', linewidth=8)\n",
        "plt.plot(x_cv_2, loss_cv_2['loss_mask'], color='blue', linewidth=8)\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylim([0.2, 0.9])\n",
        "\n",
        "plt.subplot(2, 6, 11)\n",
        "plt.plot(x_tr_2, loss_tr_2['loss_objectness'], color='lightgreen', linewidth=8)\n",
        "plt.plot(x_cv_2, loss_cv_2['loss_objectness'], color='blue', linewidth=8)\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylim([0, 0.7])\n",
        "\n",
        "plt.subplot(2, 6, 12)\n",
        "plt.plot(x_tr_2, loss_tr_2['loss_rpn_box_reg'], color='lightgreen', linewidth=8)\n",
        "plt.plot(x_cv_2, loss_cv_2['loss_rpn_box_reg'], color='blue', linewidth=8)\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylim([0, 0.3])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "87d1rz74g6D4"
      },
      "source": [
        "# Create testing dataset (same for both models, no need to replicate)\n",
        "test_dataset = my_dataset(\n",
        "      annotations_path, \n",
        "      images_path, \n",
        "      mode='tt',\n",
        "      class_sel=1,\n",
        "      )"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DnvfKDfPAKZN"
      },
      "source": [
        "# Gathering results from models\n",
        "model_1.eval()\n",
        "model_2.eval()\n",
        "cpu_device = torch.device(\"cpu\")\n",
        "model_1.to(cpu_device)\n",
        "model_2.to(cpu_device)\n",
        "\n",
        "# Select mode and mask threshold\n",
        "mode = 'tt'  # 'cv' for validation, 'tt' for testing\n",
        "threshold = 0.5  # mask value threshold for forming the polygons and binary masks\n",
        "\n",
        "# Testing and validation datasets are the same for both models, no need to replicate\n",
        "if mode == 'cv':\n",
        "  num_images = 6\n",
        "  eval_dataset = val_dataset_1\n",
        "else:\n",
        "  num_images = 9\n",
        "  eval_dataset = test_dataset\n",
        "\n",
        "# Create polygons and prepare results\n",
        "def create_polygon_and_binary_mask(mask):\n",
        "\n",
        "  # Create polygon and binary mask\n",
        "  mask_ = copy.copy(mask)\n",
        "  mask_ = mask_.swapaxes(0,2).swapaxes(0,1)\n",
        "  _, mask_ = cv2.threshold(mask_, threshold, 1, cv2.THRESH_BINARY)\n",
        "  mask_ = np.array(mask_, dtype=np.uint8)\n",
        "  contours, _ = cv2.findContours(mask_, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
        "  polygon_ = np.squeeze(contours[0]).reshape(-1)\n",
        "\n",
        "  return polygon_, mask_\n",
        "\n",
        "def gather_results(model, dataset):\n",
        "\n",
        "  # Gather results for a model\n",
        "  class_sel = dataset.class_sel\n",
        "  results = {\n",
        "      'images': [],\n",
        "      'boxes': [],\n",
        "      'labels': [],\n",
        "      'masks': [],\n",
        "      'polygons': [],\n",
        "  }\n",
        "  for i in range(num_images):\n",
        "    data = dataset.get_data(i)\n",
        "    sample = dataset[i]\n",
        "    if mode == 'cv':\n",
        "      out = model([sample[0]])\n",
        "    else:\n",
        "      out = model([sample]) \n",
        "    image_ = data['image']\n",
        "    boxes_ = list(out[0]['boxes'].cpu().detach().numpy())\n",
        "    labels_ = list(out[0]['labels'].cpu().detach().numpy())\n",
        "    masks_non_binary = out[0]['masks'].cpu().detach().numpy()\n",
        "    polygons_ = []\n",
        "    masks_ = []\n",
        "    for j in range(len(masks_non_binary)):\n",
        "      polygon, mask = create_polygon_and_binary_mask(masks_non_binary[j])\n",
        "      masks_.append(mask)\n",
        "      polygons_.append(polygon)\n",
        "    results['images'].append(image_)\n",
        "    results['boxes'].append(boxes_)\n",
        "    results['labels'].append(labels_)\n",
        "    results['masks'].append(masks_)\n",
        "    results['polygons'].append(polygons_)\n",
        "\n",
        "  return results\n",
        "\n",
        "results_1 = gather_results(model_1, eval_dataset)\n",
        "results_2 = gather_results(model_2, eval_dataset)\n",
        "\n",
        "results_1_save = copy.copy(results_1)\n",
        "results_2_save = copy.copy(results_2)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RrGy_7KVhMVi"
      },
      "source": [
        "# Model combination algorithm\n",
        "boundary = 450  # boundary for selection in case of overlapping (area in pixels)\n",
        "coexistance_threhold = 0.5  # maximum percentage of area of the smaller prediction that overlaps to accept both instances\n",
        "\n",
        "final_results = {\n",
        "    'images': [],\n",
        "    'boxes': [],\n",
        "    'labels': [],\n",
        "    'masks': [],\n",
        "    'polygons': [],\n",
        "  }\n",
        "\n",
        "for i in range(num_images):\n",
        "  deleted_1 = 0\n",
        "  deleted_2 = 0\n",
        "  num_instances_1 = len(results_1['boxes'][i])\n",
        "  num_instances_2 = len(results_2['boxes'][i])\n",
        "  for j in range(num_instances_1):\n",
        "    flag = False\n",
        "    idx_del = []\n",
        "    mask_1 = results_1['masks'][i][j - deleted_1]\n",
        "    area_1 = np.sum(mask_1)\n",
        "    for k in range(num_instances_2 - deleted_2):\n",
        "      mask_2 = results_2['masks'][i][k]\n",
        "      area_2 = np.sum(mask_2)\n",
        "      mask_sum = mask_1 + mask_2\n",
        "      mask_sum = mask_sum.reshape(-1)\n",
        "      overlap = np.count_nonzero(mask_sum > 1)\n",
        "      # If masks ovelap more than the accepted percentage, apply the boundary rule\n",
        "      if np.max(mask_sum) > 1 and overlap > coexistance_threhold * min(area_1, area_2):\n",
        "        if area_1 > boundary or area_2 > boundary:\n",
        "          idx_del.append(k)\n",
        "        else:\n",
        "          del results_1['boxes'][i][j - deleted_1]\n",
        "          del results_1['labels'][i][j - deleted_1]\n",
        "          del results_1['masks'][i][j - deleted_1]\n",
        "          del results_1['polygons'][i][j - deleted_1]\n",
        "          flag = True\n",
        "          deleted_1 += 1\n",
        "          break\n",
        "    if flag is False:\n",
        "      for n in range(len(idx_del)):\n",
        "        del results_2['boxes'][i][idx_del[n] - n] \n",
        "        del results_2['labels'][i][idx_del[n] - n] \n",
        "        del results_2['masks'][i][idx_del[n] - n] \n",
        "        del results_2['polygons'][i][idx_del[n] - n]\n",
        "        deleted_2 += 1\n",
        "  for j in range(len(results_2['labels'][i])):\n",
        "    results_2['labels'][i][j] += 1\n",
        "\n",
        "  final_results['images'].append(results_1['images'][i])\n",
        "  final_results['boxes'].append(np.array(results_1['boxes'][i] + results_2['boxes'][i]))\n",
        "  final_results['labels'].append(results_1['labels'][i] + results_2['labels'][i])\n",
        "  final_results['masks'].append(results_1['masks'][i] + results_2['masks'][i])\n",
        "  final_results['polygons'].append(results_1['polygons'][i] + results_2['polygons'][i])\n",
        "\n",
        "images = final_results['images']\n",
        "boxes = final_results['boxes']\n",
        "polygons = final_results['polygons']\n",
        "masks = final_results['masks']\n",
        "labels = final_results['labels']"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8m0M6oI8B0--"
      },
      "source": [
        "# Plot functions of predictions\n",
        "\n",
        "def plot_polygons(image, polygons, labels):\n",
        "  # Plot polygons with image\n",
        "  plt.imshow(image)\n",
        "  for i in range(len(polygons)):\n",
        "    xy_vec = np.array(polygons[i]).reshape((-1, 2))\n",
        "    x_vec = np.concatenate((xy_vec[:, 0], xy_vec[0, 0]), axis=None)\n",
        "    y_vec = np.concatenate((xy_vec[:, 1], xy_vec[0, 1]), axis=None)\n",
        "    dim = [1, 2, 0]\n",
        "    colors = ['orangered', 'lightgreen', 'blue']\n",
        "    plt.plot(x_vec, y_vec, colors[dim[labels[i]-1]])\n",
        "\n",
        "def plot_mask(image, masks, labels):\n",
        "  # Plot image mask\n",
        "  mask = np.ones((image.shape[0], image.shape[1], 3), dtype=np.float32) * 0.75\n",
        "  for i in range(len(masks)):\n",
        "    mask_ = np.squeeze(masks[i])\n",
        "    dim = [1, 2, 0]\n",
        "    for j in range(3):\n",
        "      mask[:, :, j] -= mask_ * 0.75 \n",
        "    mask[:, :, dim[labels[i]-1]] += mask_ \n",
        "  plt.imshow(mask)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1tvvelp2B9TR"
      },
      "source": [
        "# Polygons plots\n",
        "if mode == 'cv':\n",
        "  plt.figure(figsize=(20, 60))\n",
        "else:\n",
        "  plt.figure(figsize=(10, 60))\n",
        "  \n",
        "for i in range(num_images):\n",
        "  if mode == 'cv':\n",
        "    plt.subplot(num_images, 2, 1+2*i)\n",
        "    plot_polygons(images[i], polygons[i], labels[i])\n",
        "    plt.xlim([0, images[i].shape[1]])\n",
        "    plt.ylim([0, images[i].shape[0]])\n",
        "    plt.subplot(num_images, 2, 2+2*i)\n",
        "    eval_dataset.plot_polygons(i)\n",
        "    plt.xlim([0, images[i].shape[1]])\n",
        "    plt.ylim([0, images[i].shape[0]])\n",
        "  else:\n",
        "    plt.subplot(num_images, 1, 1+i)\n",
        "    plot_polygons(images[i], polygons[i], labels[i])\n",
        "    plt.xlim([0, images[i].shape[1]])\n",
        "    plt.ylim([0, images[i].shape[0]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ntgi5HvPOz8z"
      },
      "source": [
        "# Mask plots\n",
        "if mode == 'cv':\n",
        "  plt.figure(figsize=(20, 60))\n",
        "else:\n",
        "  plt.figure(figsize=(10, 60))\n",
        "\n",
        "for i in range(num_images):\n",
        "  if mode == 'cv':\n",
        "    plt.subplot(num_images, 2, 1+2*i)\n",
        "    plot_mask(images[i], masks[i], labels[i])\n",
        "    plt.xlim([0, images[i].shape[1]])\n",
        "    plt.ylim([0, images[i].shape[0]])\n",
        "    plt.subplot(num_images, 2, 2+2*i)\n",
        "    eval_dataset.plot_mask(i)\n",
        "    plt.xlim([0, images[i].shape[1]])\n",
        "    plt.ylim([0, images[i].shape[0]])\n",
        "  else:\n",
        "    plt.subplot(num_images, 1, 1+i)\n",
        "    plot_mask(images[i], masks[i], labels[i])\n",
        "    plt.xlim([0, images[i].shape[1]])\n",
        "    plt.ylim([0, images[i].shape[0]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EDOQfMI86AqF"
      },
      "source": [
        "# Check number of detected instances per class in comparison to ground truth (only for validation)\n",
        "predicted = np.zeros(3, dtype=int)\n",
        "truth = np.zeros(3, dtype=int)\n",
        "if mode == 'cv':\n",
        "  for i in range(num_images):\n",
        "    for j in range(len(eval_dataset.labels_all[i])):\n",
        "      truth[eval_dataset.labels_all[i][j] - 1] += 1\n",
        "    for j in range(len(labels[i])):\n",
        "      predicted[labels[i][j] - 1] += 1\n",
        "  print('Number of predicted...  Buildings:', str(predicted[0]), ' Houses:', str(predicted[1]), 'Sheds/Garages:', str(predicted[2]))\n",
        "  print('Ground-truth number of...  Buildings:', str(truth[0]), ' Houses:', str(truth[1]), 'Sheds/Garages:', str(truth[2]))\n",
        "else:\n",
        "  print('No ground-truth results for testing!')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fcu7f8iAx7RB"
      },
      "source": [
        "# Save the results into the desired format\n",
        "\n",
        "# JSON encoder\n",
        "class my_JSONEncoder(json.JSONEncoder):\n",
        "  def default(self, obj):\n",
        "    if isinstance(obj, np.integer):\n",
        "      return int(obj)\n",
        "    elif isinstance(obj, np.floating):\n",
        "      return float(obj)\n",
        "    elif isinstance(obj, np.ndarray):\n",
        "      return obj.tolist()\n",
        "    else:\n",
        "      return super(my_JSONEncoder, self).default(obj)\n",
        "\n",
        "# Convert polygons to original image size and save results\n",
        "image_id_idx = ['6_6', '6_7', '6_8', '7_6', '7_7', '7_8', '8_6', '8_7', '8_8']\n",
        "if mode == 'tt':\n",
        "  for i in range(num_images):\n",
        "    save_dict = {\n",
        "        'filename': image_id_idx[i] + '.png',\n",
        "        'labels': [{'name': 'Buildings', 'annotations': []}, \n",
        "                   {'name': 'Houses', 'annotations': []}, \n",
        "                   {'name': 'Sheds/Garages', 'annotations': []}],\n",
        "    }\n",
        "    for j in range(len(final_results['polygons'][i])):\n",
        "      save_dict_ = {\n",
        "          'id': int(str(i) + str(j)),\n",
        "          'type': 'polygon',\n",
        "          'segmentation': list(np.array(final_results['polygons'][i][j] / eval_dataset.resize, dtype=int))\n",
        "      }\n",
        "      save_dict['labels'][final_results['labels'][i][j] - 1]['annotations'].append(save_dict_)\n",
        "    with open('/content/drive/MyDrive/Colab Notebooks/' + image_id_idx[i] + '.png-annotated.json', 'w') as f:\n",
        "      json.dump(save_dict, f, cls=my_JSONEncoder)\n",
        "else:\n",
        "  print('This step is only for testing data!')"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v4fNxYu0x-9g"
      },
      "source": [
        "# The End!\n",
        "# Thank you for considering my application.\n",
        "# Jorge J. Bennasar Vazquez"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
